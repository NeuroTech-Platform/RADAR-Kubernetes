# Default values for radar-upload-source-connector.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

replicaCount: 2

image:
  repository: radarbase/radar-connect-upload-source
  tag: 0.5.9
  pullPolicy: IfNotPresent

nameOverride: ""
fullnameOverride: ""

service:
  type: ClusterIP
  port: 80

ingress:
  enabled: false
  annotations: {}
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
  hosts:
    - host: chart-example.local
      paths: []

  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - chart-example.local

resources:
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #   cpu: 100m
  #   memory: 128Mi
  requests:
    cpu: 100m
    memory: 800Mi

nodeSelector: {}

tolerations: []

affinity: {}

# -- Zookeeper URL
zookeeper: cp-zookeeper-headless:2181
# -- Kafka broker URLs
kafka: PLAINTEXT://cp-kafka-headless:9092
# -- Number of brokers in the cluster
kafka_num_brokers: "3"
# -- Schema registry URL
schema_registry: http://cp-schema-registry:8081
# -- Host name of the Management Portal application
managementportal_host: management-portal
# -- Host name of the upload connect backend application
radar_upload_connect_backend: radar-upload-connect-backend
# -- OAuth Client Id of the Upload connector
client_id: radar_upload_connect
# -- OAuth Client secret of the Upload connector
client_secret: upload_secret
# -- How often the connector should poll for new records from upload connect backend in milliseconds.
poll_interval: 60000
# -- List of converter classes to be activated as comma separated values.
record_converter_classes: org.radarbase.connect.upload.converter.altoida.AltoidaConverterFactory,org.radarbase.connect.upload.converter.axivity.AxivityConverterFactory,org.radarbase.connect.upload.converter.oxford.WearableCameraConverterFactory,org.radarbase.connect.upload.converter.gaitup.Physilog5ConverterFactory
# -- Uploader type for converters which directly write the files bypassing the Kafka processing. e.g. images and binaries.
uploaderType: s3
# -- Target S3 endpoint, if files should be written to a location bypassing the Kafka processing.
s3Endpoint: http://minio:9000/
# -- Target S3 access key
bucketAccessKey: access_key
# -- Target S3 secret key
bucketSecretKey: secret
# -- Target S3 bucket name
targetBucketName: radar-output-storage

task:
  # -- Maximum number of source records that can be produced at a time, preventing out of memory errors.
  queueSize: 10000

connect:
  # -- Interval at which to try committing offsets for tasks. See
  offsetFlushIntervalMs: 5000
# -- Override kafka producer configs. For more details see https://docs.confluent.io/platform/current/installation/configuration/producer-configs.html
producer:
  # -- The compression type for all data generated by the producer.
  compressionType: lz4
  # -- The total bytes of memory the producer can use to buffer records waiting to be sent to the server.
  bufferMemory: 2000000
  # -- Batch size in bytes to batch records together into fewer requests when multiple records are being sent to the same partition.
  batchSize: 200000
